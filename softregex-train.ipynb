{"nbformat":4,"nbformat_minor":0,"metadata":{"jupytext":{"cell_metadata_filter":"-all","encoding":"# coding: utf-8","executable":"/usr/bin/env python","main_language":"python","notebook_metadata_filter":"-all"},"colab":{"name":"softregex-train.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnSjVLlvFocM","executionInfo":{"status":"ok","timestamp":1639371047529,"user_tz":480,"elapsed":949,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"3e1788f9-3d38-4d7c-934f-5e2f49251120"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"colab":{"base_uri":"https://localhost:8080/"},"id":"F1QPra9RE35A","executionInfo":{"status":"ok","timestamp":1639371048506,"user_tz":480,"elapsed":978,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"77a912e9-9290-413f-e0e1-96ba6fedc36f"},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/ANLP21')\n","\n","import os\n","import argparse\n","import logging\n","\n","import torch\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n","import torchtext\n","\n","import seq2seq\n","\n","from seq2seq.trainer import SupervisedTrainer, SelfCriticalTrainer\n","from seq2seq.models import EncoderRNN, DecoderRNN, Seq2seq, TopKDecoder\n","from seq2seq.loss import Perplexity, NLLLoss, PositiveLoss\n","from seq2seq.optim import Optimizer\n","from seq2seq.dataset import SourceField, TargetField\n","from seq2seq.evaluator import Predictor, Evaluator\n","from seq2seq.util.checkpoint import Checkpoint\n","import torch.nn.functional as F"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"]}]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"HfVOx1WFE35C","executionInfo":{"status":"ok","timestamp":1639377514073,"user_tz":480,"elapsed":130,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","dataset = 'NL-RX-Turk'\n","\n","# if len(sys.argv) < 1:\n","#     sys.exit(-1)\n","\n","# dataset = sys.argv[1]\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"TUUgl2eCE35D","executionInfo":{"status":"ok","timestamp":1639377514263,"user_tz":480,"elapsed":1,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","try:\n","    raw_input          # Python 2\n","except NameError:\n","    raw_input = input  # Python 3"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"DRc5ZC2iE35D","executionInfo":{"status":"ok","timestamp":1639377516406,"user_tz":480,"elapsed":1988,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","# Prepare dataset\n","src = SourceField()\n","tgt = TargetField()\n","\n","# data/kb/train/data.txt\n","#data/NL-RX-Synth/train/data.txt\n","#data/NL-RX-Turk/train/data.txt\n","\n","datasets = {\n","    'kb13': ('KB13', 35, 60),\n","    'NL-RX-Synth': ('NL-RX-Synth', 10, 40),\n","    'NL-RX-Turk': ('NL-RX-Turk', 10, 40)\n","}\n","\n","data_tuple = datasets[dataset]\n","\n","# max_len = 60\n","max_len = data_tuple[2]\n","def len_filter(example):\n","    return len(example.src) <= max_len and len(example.tgt) <= max_len\n","train = torchtext.legacy.data.TabularDataset(\n","    path='/content/drive/MyDrive/ANLP21/data/' + data_tuple[0] + '/train/data.txt', format='tsv',\n","    fields=[('src', src), ('tgt', tgt)],\n","    filter_pred=len_filter\n",")\n","dev = torchtext.legacy.data.TabularDataset(\n","    path='/content/drive/MyDrive/ANLP21/data/' + data_tuple[0] + '/val/data.txt', format='tsv',\n","    fields=[('src', src), ('tgt', tgt)],\n","    filter_pred=len_filter\n",")\n","test = torchtext.legacy.data.TabularDataset(\n","    path='/content/drive/MyDrive/ANLP21/data/' + data_tuple[0] + '/test/data.txt', format='tsv',\n","    fields=[('src', src), ('tgt', tgt)],\n","    filter_pred=len_filter\n",")\n","src.build_vocab(train, max_size=500)\n","tgt.build_vocab(train, max_size=500)\n","input_vocab = src.vocab\n","output_vocab = tgt.vocab"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"3J3Ox5YaE35E","executionInfo":{"status":"ok","timestamp":1639377516406,"user_tz":480,"elapsed":4,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","# Prepare loss\n","weight = torch.ones(len(tgt.vocab))\n","pad = tgt.vocab.stoi[tgt.pad_token]\n","\n","loss = NLLLoss(weight, pad)\n","\n","if torch.cuda.is_available():\n","    loss.cuda()\n","    \n","seq2seq_model = None\n","optimizer = None"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"0SghsMLfE35F","executionInfo":{"status":"ok","timestamp":1639377516564,"user_tz":480,"elapsed":161,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","hidden_size = 256\n","word_embedding_size = 128\n","\n","bidirectional = True\n","\n","encoder = EncoderRNN(len(src.vocab), max_len, hidden_size, dropout_p=0.1,rnn_cell='lstm',\n","                     bidirectional=bidirectional, n_layers=2, variable_lengths=True)\n","decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,rnn_cell='lstm',\n","                     dropout_p=0.25, use_attention=True, bidirectional=bidirectional, n_layers=2,\n","                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n","\n","seq2seq_model = Seq2seq(encoder, decoder)\n","if torch.cuda.is_available():\n","    seq2seq_model.cuda()\n","\n","for param in seq2seq_model.parameters():\n","    param.data.uniform_(-0.1, 0.1)\n","\n","\n","optimizer = Optimizer(torch.optim.Adam(seq2seq_model.parameters()),  max_grad_norm=5)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"YxjWlDleE35F","executionInfo":{"status":"ok","timestamp":1639377517753,"user_tz":480,"elapsed":91,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","seq2seq_model = torch.nn.DataParallel(seq2seq_model)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5dgRCD7J24J","executionInfo":{"status":"ok","timestamp":1639377518080,"user_tz":480,"elapsed":141,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["model_out_dir = '/content/drive/MyDrive/ANLP21/lstm_model/'+data_tuple[0]+'/Deepregex'\n","!mkdir -p $model_out_dir"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"npPhS_dGE35G","executionInfo":{"status":"ok","timestamp":1639377518081,"user_tz":480,"elapsed":3,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","# train\n","\n","t = SupervisedTrainer(loss=loss, batch_size=8,\n","                      checkpoint_every=200,\n","                      print_every=10000, expt_dir=model_out_dir)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"cJzDp8tkE35H","executionInfo":{"status":"error","timestamp":1639377520363,"user_tz":480,"elapsed":1732,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"c0f49e1c-b416-44f7-809a-faae4249fcfc"},"source":[" \n","\n","seq2seq_model = t.train(seq2seq_model, train,\n","                  num_epochs=data_tuple[1], dev_data=dev,\n","                  optimizer=optimizer,\n","                  teacher_forcing_ratio=0.5,\n","                  resume=False)\n","\n","\n","# ### Self Critical Training"],"execution_count":41,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-de283ad8f177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                  \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                  resume=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/ANLP21/seq2seq/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, data, num_epochs, resume, dev_data, optimizer, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    185\u001b[0m         self._train_epoches(data, model, num_epochs,\n\u001b[1;32m    186\u001b[0m                             \u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                             teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/ANLP21/seq2seq/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36m_train_epoches\u001b[0;34m(self, data, model, n_epochs, start_epoch, start_step, dev_data, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mtarget_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_field_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;31m# Record average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/ANLP21/seq2seq/trainer/supervised_trainer.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, input_variable, input_lengths, target_variable, model, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         decoder_outputs, decoder_hidden, other = model(input_variable, input_lengths, target_variable,\n\u001b[0;32m---> 55\u001b[0;31m                                                        teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Get loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/ANLP21/seq2seq/models/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_variable, input_lengths, target_variable, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     51\u001b[0m                               \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                               \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                               teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/ANLP21/seq2seq/models/DecoderRNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_hidden, encoder_outputs, function, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    159\u001b[0m                                                                          function=function)\n\u001b[1;32m    160\u001b[0m                 \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/ANLP21/seq2seq/models/DecoderRNN.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(step, step_output, step_attn)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mret_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDecoderRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEY_ATTN_SCORE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0msymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0msequence_symbols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"lvKZW3PdE35H","executionInfo":{"status":"ok","timestamp":1639369476455,"user_tz":480,"elapsed":118,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","class compare_regex(torch.nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, target_size):\n","        super(compare_regex, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.embedding_dim = embedding_dim\n","        self.embed = Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm1 = LSTM(embedding_dim ,hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        self.lstm2 = LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        self.fc1 = Linear(hidden_dim*2*2, 60)\n","        self.fc2 = Linear(60, 20)\n","        self.fc3 = Linear(20, target_size)\n","\n","        \n","    def init_hidden(self, bs):\n","        if torch.cuda.is_available():\n","            return (torch.zeros(2, bs, self.hidden_dim).cuda(),\n","                   torch.zeros(2, bs, self.hidden_dim).cuda())\n","        else:\n","            return (torch.zeros(2, bs, self.hidden_dim),\n","                   torch.zeros(2, bs, self.hidden_dim))\n","    \n","    def forward(self, bs, line1, line2, input1_lengths,input2_lengths):\n","        embeded1 = self.embed(line1)\n","        embeded2 = self.embed(line2)\n","\n","        hidden1 = self.init_hidden(bs)\n","        lstm1_out, last_hidden1 = self.lstm1(embeded1,hidden1)\n","        hidden2 = self.init_hidden(bs)\n","        lstm2_out, last_hidden2 = self.lstm2(embeded2,hidden2)\n","\n","\n","        fc1_out = self.fc1(torch.cat((lstm1_out.mean(1), lstm2_out.mean(1)),1))  #encoder outputs 평균값 concat 97.8%\n","\n","        \n","        fc1_out = F.tanh(fc1_out)\n","        fc2_out = self.fc2(fc1_out)\n","        fc2_out = F.tanh(fc2_out)\n","        fc3_out = self.fc3(fc2_out)\n","        score = F.log_softmax(fc3_out,dim=1)\n","        return score"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCNo6LrnRAGj","executionInfo":{"status":"ok","timestamp":1639377526768,"user_tz":480,"elapsed":4508,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"571dd61a-5429-44fd-b087-f54260b8dfda"},"source":["!pip install transformers\n"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"gd8daU5_Qz6N","executionInfo":{"status":"ok","timestamp":1639377526943,"user_tz":480,"elapsed":178,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import LSTM,Embedding,Linear\n","from torch.nn import Module\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from transformers import BertModel, BertTokenizerFast, RobertaTokenizerFast, RobertaModel\n","reberth_path = \"/content/drive/MyDrive/ANLP21/ReBERTh\"\n","compare_model_dir = f\"/content/drive/MyDrive/ANLP21/ReBERTh/compare/base\"\n","\n","class compare_regex_bert(torch.nn.Module):\n","    tokenizer = RobertaTokenizerFast.from_pretrained(compare_model_dir, do_lower_case=False, do_basic_tokenize=False)\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, target_size):\n","        super(compare_regex_bert, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.embedding_dim = embedding_dim\n","        self.embed = Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        # self.lstm1 = LSTM(embedding_dim ,hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        # self.lstm2 = LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        # self.model_name=params[\"model_name\"]\n","        # self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", do_lower_case=False, do_basic_tokenize=False)\n","        self.bert1 = RobertaModel.from_pretrained(reberth_path)\n","        self.bert2 = RobertaModel.from_pretrained(reberth_path)\n","\n","        self.bert1.resize_token_embeddings(len(self.tokenizer))\n","        self.bert2.resize_token_embeddings(len(self.tokenizer))\n","\n","        # self.fc = Linear(embedding_dim*2*2, hidden_dim*2*2)\n","        self.fc1 = Linear(embedding_dim*2, 60)\n","        self.fc2 = Linear(60, 20)\n","        self.fc3 = Linear(20, target_size)\n","\n","        \n","    def init_hidden(self, bs):\n","        if torch.cuda.is_available():\n","            return (torch.zeros(2, bs, self.hidden_dim).cuda(),\n","                   torch.zeros(2, bs, self.hidden_dim).cuda())\n","        else:\n","            return (torch.zeros(2, bs, self.hidden_dim),\n","                   torch.zeros(2, bs, self.hidden_dim))\n","    \n","    def forward(self, bs, line1, line2, input1_lengths,input2_lengths):\n","        # embeded1 = self.embed(line1)\n","        # embeded2 = self.embed(line2)\n","\n","\n","\n","        # hidden1 = self.init_hidden(bs)\n","        # lstm1_out, last_hidden1 = self.lstm1(embeded1,hidden1)\n","        # hidden2 = self.init_hidden(bs)\n","        # lstm2_out, last_hidden2 = self.lstm2(embeded2,hidden2)\n","        # print(line1)\n","        # print(line2)\n","        # bert1_output = self.bert1(input_ids=line1[\"input_ids\"],\n","        #                  attention_mask=line1[\"attention_mask\"],\n","        #                  token_type_ids=line1[\"token_type_ids\"],\n","        #                  output_hidden_states=True)\n","        # bert1_hidden_states = bert1_output['hidden_states']\n","        # bert1_out = bert1_hidden_states[-1][:,0,:]\n","\n","        bert1_output = self.bert1(**line1)\n","        bert1_out = bert1_output.last_hidden_state\n","\n","        bert2_output = self.bert2(**line2)\n","        bert2_out = bert2_output.last_hidden_state\n","        # bert2_output = self.bert2(input_ids=line2[\"input_ids\"],\n","        #                  attention_mask=line2[\"attention_mask\"],\n","        #                  token_type_ids=line2[\"token_type_ids\"],\n","        #                  output_hidden_states=True)\n","        # bert2_hidden_states = bert2_output['hidden_states']\n","        # bert2_out = bert2_hidden_states[-1][:,0,:]\n","\n","        # print(bert1_out.shape)\n","        # print(bert1_out.mean(1).shape)\n","        # print(bert2_out.shape)\n","        # print(bert2_out.mean(1).shape)\n","        fc1_out = self.fc1(torch.cat((bert1_out.mean(1), bert2_out.mean(1)),1))  #encoder outputs 평균값 concat 97.8%\n","        \n","        fc1_out = F.tanh(fc1_out)\n","        fc2_out = self.fc2(fc1_out)\n","        fc2_out = F.tanh(fc2_out)\n","        fc3_out = self.fc3(fc2_out)\n","        score = F.log_softmax(fc3_out,dim=1)\n","        return score"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"colab":{"base_uri":"https://localhost:8080/"},"id":"4muFOAIaE35I","executionInfo":{"status":"ok","timestamp":1639377528221,"user_tz":480,"elapsed":1280,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"ef201528-0d91-4368-a3ee-a18a7e4a1842"},"source":["\n","\n","f = open('/content/drive/MyDrive/ANLP21/compare_vocab.txt')\n","sc_loss_vocab = dict()\n","for line in f.read().splitlines():\n","    line = line.split('\\t')\n","    sc_loss_vocab[line[0]] = int(line[1])\n","f.close()\n","# compare_regex_model = compare_regex_bert(32, 768, 256, 2).cuda()\n","compare_regex_model = torch.load('/content/drive/MyDrive/ANLP21/ReBERTh/compare/base/epoch-0.pth', map_location=torch.device('cuda'))\n","# compare_regex_model.load_state_dict(torch.load('/content/drive/MyDrive/ANLP21/ReBERTh/compare/base/epoch-0.pth'))\n","compare_regex_model.eval()\n","# compare_regex_model.eval()\n","# compare_regex_model"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["compare_regex_bert(\n","  (embed): Embedding(32, 768, padding_idx=0)\n","  (bert1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(1009, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert2): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(1009, 768)\n","      (position_embeddings): Embedding(512, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc1): Linear(in_features=1536, out_features=60, bias=True)\n","  (fc2): Linear(in_features=60, out_features=20, bias=True)\n","  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"genOxMhTOmT1","executionInfo":{"status":"ok","timestamp":1639377529291,"user_tz":480,"elapsed":273,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["model_out_dir = '/content/drive/MyDrive/ANLP21/lstm_model/'+data_tuple[0]+'/SoftRegex'\n","!mkdir -p $model_out_dir"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"-xNhW9mpE35I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639380955674,"user_tz":480,"elapsed":3426223,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"cf18e38e-28a3-4b39-ef15-f124cd4441cf"},"source":["\n","\n","optimizer_new = Optimizer(torch.optim.Adadelta(seq2seq_model.parameters(), lr=0.05))\n","\n","#if you want to train by oracle, put mode to None\n","sc_t = SelfCriticalTrainer(loss=PositiveLoss(mode='prob', prob_model=compare_regex_model, loss_vocab=sc_loss_vocab), batch_size=32,\n","                           checkpoint_every=100, print_every=100, expt_dir=model_out_dir, output_vocab=output_vocab)\n","\n","\n","\n","seq2seq_model = sc_t.train(seq2seq_model, train,\n","                  num_epochs=10, dev_data=dev,\n","                  optimizer=optimizer_new, teacher_forcing_ratio=0.5,\n","                  resume=False)"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, time: 6.75519307454427e-08\n","Progress: 9%, Train Random Positive Acceptance Reward: 18.8617\n","Finished epoch 1: Train Random Positive Acceptance Reward: 9.2470, Dev Random Positive Acceptance Reward: 13.8043, Accuracy: 0.2077\n","epoch: 2, time: 5.707986787954966\n","Progress: 14%, Train Random Positive Acceptance Reward: 0.0367\n","Progress: 19%, Train Random Positive Acceptance Reward: 0.0020\n","Finished epoch 2: Train Random Positive Acceptance Reward: 0.0206, Dev Random Positive Acceptance Reward: 15.5908, Accuracy: 0.2077\n","epoch: 3, time: 11.440361018975576\n","Progress: 24%, Train Random Positive Acceptance Reward: 0.0104\n","Progress: 29%, Train Random Positive Acceptance Reward: 0.0140\n","Finished epoch 3: Train Random Positive Acceptance Reward: 0.0094, Dev Random Positive Acceptance Reward: 16.3350, Accuracy: 0.2077\n","epoch: 4, time: 17.125614364941914\n","Progress: 34%, Train Random Positive Acceptance Reward: 0.0117\n","Progress: 39%, Train Random Positive Acceptance Reward: 0.0045\n","Finished epoch 4: Train Random Positive Acceptance Reward: 0.0079, Dev Random Positive Acceptance Reward: 17.0112, Accuracy: 0.2077\n","epoch: 5, time: 22.845337065060935\n","Progress: 44%, Train Random Positive Acceptance Reward: 0.0003\n","Progress: 49%, Train Random Positive Acceptance Reward: 0.0060\n","Finished epoch 5: Train Random Positive Acceptance Reward: 0.0048, Dev Random Positive Acceptance Reward: 17.3625, Accuracy: 0.2077\n","epoch: 6, time: 28.536050681273142\n","Progress: 53%, Train Random Positive Acceptance Reward: 0.0053\n","Progress: 58%, Train Random Positive Acceptance Reward: 0.0067\n","Finished epoch 6: Train Random Positive Acceptance Reward: 0.0042, Dev Random Positive Acceptance Reward: 17.7605, Accuracy: 0.2077\n","epoch: 7, time: 34.25831749836604\n","Progress: 63%, Train Random Positive Acceptance Reward: 0.0035\n","Progress: 68%, Train Random Positive Acceptance Reward: 0.0021\n","Finished epoch 7: Train Random Positive Acceptance Reward: 0.0033, Dev Random Positive Acceptance Reward: 18.1779, Accuracy: 0.2077\n","epoch: 8, time: 39.96884721517563\n","Progress: 73%, Train Random Positive Acceptance Reward: 0.0042\n","Progress: 78%, Train Random Positive Acceptance Reward: 0.0021\n","Finished epoch 8: Train Random Positive Acceptance Reward: 0.0026, Dev Random Positive Acceptance Reward: 18.4721, Accuracy: 0.2077\n","epoch: 9, time: 45.658922831217446\n","Progress: 83%, Train Random Positive Acceptance Reward: 0.0031\n","Progress: 88%, Train Random Positive Acceptance Reward: 0.0007\n","Finished epoch 9: Train Random Positive Acceptance Reward: 0.0018, Dev Random Positive Acceptance Reward: 18.7389, Accuracy: 0.2077\n","epoch: 10, time: 51.376916992664334\n","Progress: 93%, Train Random Positive Acceptance Reward: 0.0001\n","Progress: 98%, Train Random Positive Acceptance Reward: 0.0021\n","Finished epoch 10: Train Random Positive Acceptance Reward: 0.0013, Dev Random Positive Acceptance Reward: 18.9391, Accuracy: 0.2077\n"]}]},{"cell_type":"code","metadata":{"lines_to_next_cell":2,"id":"kyPY25RTE35J","executionInfo":{"status":"aborted","timestamp":1639377450132,"user_tz":480,"elapsed":262,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","evaluator = Evaluator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAv2AKeTE35J","executionInfo":{"status":"aborted","timestamp":1639377450133,"user_tz":480,"elapsed":263,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["\n","\n","evaluator.evaluate(seq2seq_model, test) # (5.799417234628771, 0.6468332123976366)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"oXNP72yNLndm"},"execution_count":null,"outputs":[]}]}