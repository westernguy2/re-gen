{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"compare_regex.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"xKqFS9WVl8jJ","executionInfo":{"status":"error","timestamp":1639339789190,"user_tz":480,"elapsed":177,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"37e26f3d-ac9b-4d7d-c0f1-ba174a716941"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5968/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}]},{"cell_type":"code","metadata":{"id":"RbMBcD4jp3t5","executionInfo":{"status":"aborted","timestamp":1639339789187,"user_tz":480,"elapsed":290,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["!pip install transformers\n","!pip install tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["size_name = \"base\"\n","reberth_path = \"G:\\\\My Drive\\\\ANLP21\\\\\\ReBERTh\\\\base\"\n","data_path = \"G:\\\\My Drive\\\\ANLP21\\\\regex_data\"\n","compare_model_dir = \"G:\\\\My Drive\\\\ANLP21\\\\ReBERTh\\\\compare\\\\base\""],"metadata":{"id":"etT_UriuN1Ps","executionInfo":{"status":"ok","timestamp":1639342721496,"user_tz":480,"elapsed":13,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6_J-qDeMFfY","executionInfo":{"status":"aborted","timestamp":1639339789322,"user_tz":480,"elapsed":415,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["size_name = \"base\"\n","reberth_path = f\"/content/drive/MyDrive/ANLP21/ReBERTh/{size_name}\"\n","data_path = \"/content/drive/MyDrive/ANLP21/regex_data\"\n","compare_model_dir = f\"/content/drive/MyDrive/ANLP21/ReBERTh/compare/base\"\n","!mkdir -p $compare_model_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPgWgfj3b27u","executionInfo":{"status":"ok","timestamp":1639342700331,"user_tz":480,"elapsed":116,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"cae1f8ff-cd34-40b5-9931-d41ed7d5923d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 12 12:58:20 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n","|  0%   33C    P8    15W / 200W |    579MiB /  8192MiB |      3%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A       984    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n","|    0   N/A  N/A      2980    C+G   ...obeNotificationClient.exe    N/A      |\n","|    0   N/A  N/A      3368    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n","|    0   N/A  N/A      3752    C+G   ...artMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A      4352    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n","|    0   N/A  N/A      7256    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n","|    0   N/A  N/A      7764    C+G   ...batNotificationClient.exe    N/A      |\n","|    0   N/A  N/A      8088    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n","|    0   N/A  N/A      8176    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A      8384    C+G   ...3.0.8.0\\GoogleDriveFS.exe    N/A      |\n","|    0   N/A  N/A     11352    C+G   Insufficient Permissions        N/A      |\n","|    0   N/A  N/A     11432    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n","|    0   N/A  N/A     16136    C+G   ...lack\\app-4.23.0\\slack.exe    N/A      |\n","|    0   N/A  N/A     17084    C+G   ...me\\Application\\chrome.exe    N/A      |\n","|    0   N/A  N/A     17792    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     18780    C+G   ...ram Files\\LGHUB\\lghub.exe    N/A      |\n","|    0   N/A  N/A     19208    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A     19952    C+G   ...EarTrumpet\\EarTrumpet.exe    N/A      |\n","|    0   N/A  N/A     21600    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"1PNh5ooml0l5","executionInfo":{"status":"ok","timestamp":1639342739647,"user_tz":480,"elapsed":14497,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn import LSTM,Embedding,Linear\n","from torch.nn import Module\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from transformers import BertModel, BertTokenizerFast, RobertaTokenizerFast, RobertaModel\n","import tqdm\n","\n","class compare_regex(torch.nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, target_size):\n","        super(compare_regex, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.embedding_dim = embedding_dim\n","        self.embed = Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm1 = LSTM(embedding_dim ,hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        self.lstm2 = LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        self.fc1 = Linear(hidden_dim*2*2, 60)\n","        self.fc2 = Linear(60, 20)\n","        self.fc3 = Linear(20, target_size)\n","\n","        \n","    def init_hidden(self, bs):\n","        if torch.cuda.is_available():\n","            return (torch.zeros(2, bs, self.hidden_dim).cuda(),\n","                   torch.zeros(2, bs, self.hidden_dim).cuda())\n","        else:\n","            return (torch.zeros(2, bs, self.hidden_dim),\n","                   torch.zeros(2, bs, self.hidden_dim))\n","    \n","    def forward(self, bs, line1, line2, input1_lengths,input2_lengths):\n","        embeded1 = self.embed(line1)\n","        embeded2 = self.embed(line2)\n","        hidden1 = self.init_hidden(bs)\n","        lstm1_out, last_hidden1 = self.lstm1(embeded1,hidden1)\n","        hidden2 = self.init_hidden(bs)\n","        lstm2_out, last_hidden2 = self.lstm1(embeded2,hidden2)\n","        fc1_out = self.fc1(torch.cat((lstm1_out.mean(1), lstm2_out.mean(1)),1))\n","\n","        fc1_out = F.tanh(fc1_out)\n","        fc2_out = self.fc2(fc1_out)\n","        fc2_out = F.tanh(fc2_out)\n","        fc3_out = self.fc3(fc2_out)\n","        score = F.log_softmax(fc3_out,dim=1)\n","        return score"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogm50KCIoqLh","executionInfo":{"status":"ok","timestamp":1639342739772,"user_tz":480,"elapsed":124,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["class compare_regex_bert(torch.nn.Module):\n","    tokenizer = RobertaTokenizerFast.from_pretrained(compare_model_dir, do_lower_case=False, do_basic_tokenize=False)\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, target_size):\n","        super(compare_regex_bert, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.embedding_dim = embedding_dim\n","        self.embed = Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        # self.lstm1 = LSTM(embedding_dim ,hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        # self.lstm2 = LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n","        # self.model_name=params[\"model_name\"]\n","        # self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\", do_lower_case=False, do_basic_tokenize=False)\n","        self.bert1 = RobertaModel.from_pretrained(reberth_path)\n","        self.bert2 = RobertaModel.from_pretrained(reberth_path)\n","\n","        self.bert1.resize_token_embeddings(len(self.tokenizer))\n","        self.bert2.resize_token_embeddings(len(self.tokenizer))\n","\n","        # self.fc = Linear(embedding_dim*2*2, hidden_dim*2*2)\n","        self.fc1 = Linear(embedding_dim*2, 60)\n","        self.fc2 = Linear(60, 20)\n","        self.fc3 = Linear(20, target_size)\n","\n","        \n","    def init_hidden(self, bs):\n","        if torch.cuda.is_available():\n","            return (torch.zeros(2, bs, self.hidden_dim).cuda(),\n","                   torch.zeros(2, bs, self.hidden_dim).cuda())\n","        else:\n","            return (torch.zeros(2, bs, self.hidden_dim),\n","                   torch.zeros(2, bs, self.hidden_dim))\n","    \n","    def forward(self, line1, line2):\n","        # embeded1 = self.embed(line1)\n","        # embeded2 = self.embed(line2)\n","\n","\n","\n","        # hidden1 = self.init_hidden(bs)\n","        # lstm1_out, last_hidden1 = self.lstm1(embeded1,hidden1)\n","        # hidden2 = self.init_hidden(bs)\n","        # lstm2_out, last_hidden2 = self.lstm2(embeded2,hidden2)\n","        # print(line1)\n","        # print(line2)\n","\n","        # bert1_output = self.bert1(input_ids=line1[\"input_ids\"],\n","        #                  attention_mask=line1[\"attention_mask\"],\n","        #                  token_type_ids=line1[\"token_type_ids\"],\n","        #                  output_hidden_states=True)\n","        # bert1_hidden_states = bert1_output['hidden_states']\n","        # bert1_out = bert1_hidden_states[-1][:,0,:]\n","\n","        bert1_output = self.bert1(**line1)\n","        bert1_out = bert1_output.last_hidden_state\n","\n","        bert2_output = self.bert2(**line2)\n","        bert2_out = bert2_output.last_hidden_state\n","        # bert2_output = self.bert2(input_ids=line2[\"input_ids\"],\n","        #                  attention_mask=line2[\"attention_mask\"],\n","        #                  token_type_ids=line2[\"token_type_ids\"],\n","        #                  output_hidden_states=True)\n","        # bert2_hidden_states = bert2_output['hidden_states']\n","        # bert2_out = bert2_hidden_states[-1][:,0,:]\n","\n","\n","        fc1_out = self.fc1(torch.cat((bert1_out.mean(1), bert2_out.mean(1)),1))  #encoder outputs 평균값 concat 97.8%\n","\n","        \n","        fc1_out = F.tanh(fc1_out)\n","        fc2_out = self.fc2(fc1_out)\n","        fc2_out = F.tanh(fc2_out)\n","        fc3_out = self.fc3(fc2_out)\n","        score = F.log_softmax(fc3_out,dim=1)\n","        return score"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHsnSYTkl0mM"},"source":["======================================================================================"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VjRg3Z3Ll0nz","executionInfo":{"status":"ok","timestamp":1639342740407,"user_tz":480,"elapsed":623,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"db4d910c-e4f5-44ea-c6f0-ef8078b17810"},"source":["# f = open('/content/drive/MyDrive/ANLP21/train_data.txt','r')\n","f = open(\"G:\\\\My Drive\\\\ANLP21\\\\train_data.txt\",'r')\n","\n","total_set = set()\n","lines1 = list()\n","lines2 = list()\n","targets = list()\n","\n","\n","for line in f.read().splitlines():\n","    splitted = line.split('\\t')\n","    a = '{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2])\n","    if not a in total_set:\n","        total_set.add(line)\n","        \n","train_lines1 = list()\n","train_lines2 = list()\n","train_targets = list()\n","for line in total_set:\n","    splitted = line.split('\\t')\n","    train_lines1.append(splitted[0])\n","    train_lines2.append(splitted[1])\n","    train_targets.append(splitted[2])\n","    train_lines1.append(splitted[1])\n","    train_lines2.append(splitted[0])\n","    train_targets.append(splitted[2])\n","print(train_lines1[0])"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["( ( <M0> ) ( . * ) ) & ( \\ b [ <VOW> ] \\ b )\n"]}]},{"cell_type":"code","metadata":{"id":"5dJKfAgel0oC","executionInfo":{"status":"ok","timestamp":1639342740439,"user_tz":480,"elapsed":31,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["# f = open('/content/drive/MyDrive/ANLP21/test_data.txt','r')\n","f = open(\"G:\\\\My Drive\\\\ANLP21\\\\test_data.txt\",'r')\n","\n","total_set = set()\n","lines1 = list()\n","lines2 = list()\n","targets = list()\n","\n","\n","for line in f.read().splitlines():\n","    splitted = line.split('\\t')\n","    a = '{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2])\n","    if not a in total_set:\n","        total_set.add(line)\n","        \n","test_lines1 = list()\n","test_lines2 = list()\n","test_targets = list()\n","for line in total_set:\n","    splitted = line.split('\\t')\n","    test_lines1.append(splitted[0])\n","    test_lines2.append(splitted[1])\n","    test_targets.append(splitted[2])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"MCdYRInbl0oP","executionInfo":{"status":"ok","timestamp":1639342740454,"user_tz":480,"elapsed":13,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["# #delete cell\n","# f = open('../pair_data/data_pairs_test(4_depth).txt','r')\n","# # f = open('../pair_data/test_data.txt','r')\n","\n","# total_set = set()\n","# lines1 = list()\n","# lines2 = list()\n","# targets = list()\n","\n","\n","# for line in f.read().splitlines():\n","#     splitted = line.split('\\t')\n","#     a = '{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2])\n","#     if not a in total_set:\n","#         total_set.add(line)\n","        \n","# test_lines1 = list()\n","# test_lines2 = list()\n","# test_targets = list()\n","# for line in total_set:\n","#     splitted = line.split('\\t')\n","#     test_lines1.append(splitted[0])\n","#     test_lines2.append(splitted[1])\n","#     test_targets.append(splitted[2])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rn6WfAwl0pC","executionInfo":{"status":"ok","timestamp":1639342740486,"user_tz":480,"elapsed":15,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"bd7536a5-0085-4e32-ee42-450cfddc8668"},"source":["print(len(train_lines1))\n","print(len(test_lines1))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["372728\n","5297\n"]}]},{"cell_type":"markdown","metadata":{"id":"KhV7xumql0pM"},"source":["=================================================================================================="]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Phjn9xg3l0pP","executionInfo":{"status":"ok","timestamp":1639342741102,"user_tz":480,"elapsed":486,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"fe13c4e5-0561-496f-b231-212da43f2a4d"},"source":["vocab = {w:i for i,w in enumerate(set([t for s in train_lines1 for t in s.split(' ')]), 1)}\n","vocab['<pad>'] = 0\n","vocab_size = len(vocab)\n","print(len(vocab))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["31\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mOYBk5hVl0qK","executionInfo":{"status":"ok","timestamp":1639342741119,"user_tz":480,"elapsed":15,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"898b06ad-c59b-460f-b378-fea0a37795c6"},"source":["print(vocab)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{'b': 1, '[': 2, '<CAP>': 3, '{': 4, '<M3>': 5, '4': 6, '\\\\': 7, '&': 8, '<NUM>': 9, '<M1>': 10, '2': 11, '<M0>': 12, ']': 13, '|': 14, '<LOW>': 15, '+': 16, '<VOW>': 17, '}': 18, '6': 19, '~': 20, '<LET>': 21, '(': 22, ')': 23, '5': 24, '.': 25, '<M2>': 26, ',': 27, '3': 28, '*': 29, '7': 30, '<pad>': 0}\n"]}]},{"cell_type":"code","metadata":{"id":"MIQl9Lu-l0qM","executionInfo":{"status":"ok","timestamp":1639342741193,"user_tz":480,"elapsed":14,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["# f_w = open('./compare_vocab(uncleaned).txt','w')\n","# for i in vocab.items():\n","#     f_w.write('{}\\t{}\\n'.format(i[0],i[1]))\n","# f_w.close()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCMi1qffl0qO","executionInfo":{"status":"ok","timestamp":1639342742272,"user_tz":480,"elapsed":42,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"bae8ce32-3b9d-4f9d-d91e-284319f314be"},"source":["vocab = {}\n","# f = open('/content/drive/MyDrive/ANLP21/compare_vocab.txt','r')\n","f = open('G:\\\\My Drive\\\\ANLP21\\\\compare_vocab.txt','r')\n","\n","for i in f.read().splitlines():\n","    splitted = i.split('\\t')\n","    vocab[splitted[0]] = int(splitted[1])\n","vocab_size = len(vocab)\n","compare_regex_bert.tokenizer.add_tokens(list(vocab.keys()))"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"8NxOHgk6l0qP","executionInfo":{"status":"ok","timestamp":1639342796199,"user_tz":480,"elapsed":47720,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["import random\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def make_input_seq(lines1, lines2, targets):\n","    \n","    max_len = 40\n","    lines1_seq2idx = list()\n","    lines2_seq2idx = list()\n","    targets_idx = list()\n","    lines1_seq = [s.split() for s in lines1]\n","    lines2_seq = [s.split() for s in lines2]\n","    for line_num in range(len(lines1_seq)):\n","        if len(lines1_seq[line_num]) > max_len or len(lines2_seq[line_num]) > max_len:\n","            continue\n","        # lines1_padded = lines1_seq[line_num]+['<pad>']*(max_len-len(lines1_seq[line_num]))\n","        # lines2_padded = lines2_seq[line_num]+['<pad>']*(max_len-len(lines2_seq[line_num]))\n","        # lines1_seq2idx.append([vocab[i] for i in lines1_padded])\n","        # lines2_seq2idx.append([vocab[i] for i in lines2_padded])\n","        \n","        # lines1_tokenized = compare_regex_bert.tokenizer(lines1, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n","        # lines2_tokenized = compare_regex_bert.tokenizer(lines2, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n","        \n","        if targets[line_num] == '0':\n","            targets_idx.append([1,0])\n","        else:\n","            targets_idx.append([0,1])\n","    lines1_tokenized = compare_regex_bert.tokenizer(lines1, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n","    lines2_tokenized = compare_regex_bert.tokenizer(lines2, padding=True, truncation=True, return_tensors=\"pt\", max_length=256)\n","    if torch.cuda.is_available():\n","        return lines1_tokenized.to(device), lines2_tokenized.to(device), torch.LongTensor(targets_idx).cuda()\n","    else:\n","        return lines1_tokenized, lines2_tokenized, torch.LongTensor(targets_idx)\n","    # return lines1_tokenized, lines2_tokenized, torch.LongTensor(targets_idx)\n","        \n","\n","\n","lines1_seq2idx, lines2_seq2idx, targets_idx = make_input_seq(train_lines1, train_lines2, train_targets)\n","test_input1, test_input2, test_targets = make_input_seq(test_lines1, test_lines2, test_targets)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmbnznLnl0qR","executionInfo":{"status":"ok","timestamp":1639342796276,"user_tz":480,"elapsed":14,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"4700a229-716f-47c8-f20c-278773131ad5"},"source":["print(len(lines1_seq2idx))\n","print(len(lines2_seq2idx))\n","print(len(test_targets))\n","print(test_targets.tolist().count([1,0]))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","2\n","5297\n","2500\n"]}]},{"cell_type":"code","metadata":{"id":"97O_DcREl0qS","executionInfo":{"status":"ok","timestamp":1639342796306,"user_tz":480,"elapsed":29,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["import torch.optim as optim\n","import time"],"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def confusion(prediction, truth):\n","    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n","    tensors, i.e. the amount of positions where the values of `prediction`\n","    and `truth` are\n","    - 1 and 1 (True Positive)\n","    - 1 and 0 (False Positive)\n","    - 0 and 0 (True Negative)\n","    - 0 and 1 (False Negative)\n","    \"\"\"\n","\n","    confusion_vector = prediction / truth\n","    # Element-wise division of the 2 tensors returns a new tensor which holds a\n","    # unique value for each case:\n","    #   1     where prediction and truth are 1 (True Positive)\n","    #   inf   where prediction is 1 and truth is 0 (False Positive)\n","    #   nan   where prediction and truth are 0 (True Negative)\n","    #   0     where prediction is 0 and truth is 1 (False Negative)\n","\n","    true_positives = torch.sum(confusion_vector == 1).item()\n","    false_positives = torch.sum(confusion_vector == float('inf')).item()\n","    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n","    false_negatives = torch.sum(confusion_vector == 0).item()\n","\n","    return true_positives, false_positives, true_negatives, false_negatives"],"metadata":{"id":"eNjQLSCav0QF","executionInfo":{"status":"ok","timestamp":1639342796317,"user_tz":480,"elapsed":9,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EOtTd9Bl0qT","executionInfo":{"status":"ok","timestamp":1639342796334,"user_tz":480,"elapsed":5,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["from transformers import tokenization_utils_base\n","\n","batch_size = 64\n","def evaluate_test(model, test_input1, test_input2 , test_target):\n","    correct = 0\n","    print(len(test_target))\n","    tp=0\n","    tn=0\n","    fp=0\n","    fn=0\n","    batch_num = int(len(test_lines1)/batch_size)\n","    for batch in range(batch_num):\n","        # test_input1_len = torch.tensor([torch.max(test_input1[i].data.nonzero()+1)])\n","        # test_input2_len = torch.tensor([torch.max(test_input2[i].data.nonzero()+1)])\n","        # score = model(1, test_input1[i].unsqueeze(0), test_input2[i].unsqueeze(0) , test_input1_len.tolist(), test_input2_len.tolist())\n","        lines1_batch = {k: v[batch * batch_size:(batch+1) * batch_size] for k, v in test_input1.items()}\n","        lines2_batch = {k: v[batch * batch_size:(batch+1) * batch_size] for k, v in test_input2.items()}\n","        targets_batches = targets_idx[batch * batch_size:(batch+1) * batch_size].to(device)\n","        score = model(lines1_batch, lines2_batch)\n","\n","        true_pos, false_pos, true_neg, false_neg = confusion(score.argmax(dim=1), targets_batches[:, 1])\n","        tp += true_pos\n","        fp += false_pos\n","        tn += true_neg\n","        fn += false_neg\n","        # print(score.argmax(dim=1))\n","    #     if score.argmax().item() == 1 and test_target[i].argmax().item()==1:\n","    #         tp+=1\n","    #     elif score.argmax().item() == 0 and test_target[i].argmax().item()==0:\n","    #         tn+=1\n","    #     elif score.argmax().item() == 1 and test_target[i].argmax().item()==0:\n","    #         fp+=1\n","    #     elif score.argmax().item() == 0 and test_target[i].argmax().item()==1:\n","    #         fn+=1\n","    #     if score.argmax().item() == test_target[i].argmax().item():\n","    #         correct += 1\n","    try:\n","        precision =  tp/(tp+fp)\n","        recall =  tp/(tp+fn)\n","        f1_score = 2*((precision*recall)/(precision+recall))\n","        correct = tp + tn\n","    except:\n","        precision = 0\n","        recall = 0\n","        f1_score = 0\n","    print('precision: {},recall: {},f1 score:{}'.format(precision,recall,f1_score))\n","    print('total: {}, correct: {}'.format(len(test_target), correct))\n","    return correct/len(test_target)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uchCkC-pl0qW","executionInfo":{"status":"ok","timestamp":1639342832946,"user_tz":480,"elapsed":2681,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"e3fe0e94-1e11-4ab2-dc55-3013dd5bfb82"},"source":["import os\n","print(torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    # compare_regex_model = compare_regex_bert(vocab_size, 256, 256, 2).cuda()\n","    # compare_regex_model = compare_regex_bert(vocab_size, 768, 256, 2).cuda()\n","    compare_regex_model = torch.load(os.path.join(compare_model_dir, \"epoch-1-batch-1000.pth\"))\n","else:\n","    compare_regex_model = compare_regex_bert(vocab_size, 768, 256, 2)\n","    # compare_regex_model = compare_regex_bert(vocab_size, 256, 256, 2)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"AJzRzn6Zdpj2","executionInfo":{"status":"ok","timestamp":1639343107659,"user_tz":480,"elapsed":13,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cyvlx1gnXAMC","executionInfo":{"status":"ok","timestamp":1639343108230,"user_tz":480,"elapsed":177,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"1dbd63a9-0081-44cf-a262-e583d1ab73e0"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 12 13:05:08 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 466.77       Driver Version: 466.77       CUDA Version: 11.3     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n","|  0%   38C    P8    15W / 200W |   8093MiB /  8192MiB |      8%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A       984    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n","|    0   N/A  N/A      2980    C+G   ...obeNotificationClient.exe    N/A      |\n","|    0   N/A  N/A      3368    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n","|    0   N/A  N/A      3752    C+G   ...artMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A      4352    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n","|    0   N/A  N/A      7256    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n","|    0   N/A  N/A      7764    C+G   ...batNotificationClient.exe    N/A      |\n","|    0   N/A  N/A      8088    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n","|    0   N/A  N/A      8176    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A      8384    C+G   ...3.0.8.0\\GoogleDriveFS.exe    N/A      |\n","|    0   N/A  N/A     11352    C+G   Insufficient Permissions        N/A      |\n","|    0   N/A  N/A     11432    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n","|    0   N/A  N/A     13868      C   D:\\anaconda\\python.exe          N/A      |\n","|    0   N/A  N/A     16136    C+G   ...lack\\app-4.23.0\\slack.exe    N/A      |\n","|    0   N/A  N/A     17084    C+G   ...me\\Application\\chrome.exe    N/A      |\n","|    0   N/A  N/A     17792    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     18780    C+G   ...ram Files\\LGHUB\\lghub.exe    N/A      |\n","|    0   N/A  N/A     19208    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A     19952    C+G   ...EarTrumpet\\EarTrumpet.exe    N/A      |\n","|    0   N/A  N/A     21600    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jXixAxrWl0qa","outputId":"07147333-794e-4ae2-9056-727cc43b6ce3","executionInfo":{"status":"error","timestamp":1639342939239,"user_tz":480,"elapsed":9231,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}}},"source":["loss_function = nn.NLLLoss()\n","optimizer = optim.SGD(compare_regex_model.parameters(), lr=0.1)\n","batch_size = 64\n","\n","start_epoch, start_batch = 1, 1000\n","\n","batch_num = int(len(train_lines1)/batch_size)\n","print(\"num_batches:\", batch_num)\n","\n","compare_regex_model.train()\n","for epoch in range(start_epoch, 5):\n","    epoch_loss = 0\n","    start_time = time.time()\n","    if epoch == start_epoch and start_batch != 0:\n","      for batch in tqdm.tqdm(range(start_batch+1, batch_num)):\n","        compare_regex_model.zero_grad()\n","        # lines1_batch = lines1_seq2idx[batch * batch_size:(batch+1) * batch_size]\n","        # lines2_batch = lines2_seq2idx[batch * batch_size:(batch+1) * batch_size]\n","        lines1_batch = {k: v[batch * batch_size:(batch+1) * batch_size] for k, v in lines1_seq2idx.items()}\n","        lines2_batch = {k: v[batch * batch_size:(batch+1) * batch_size] for k, v in lines2_seq2idx.items()}\n","        # lines1_batch_lengths = torch.tensor([torch.max(lines1_batch[i].data.nonzero()+1) for i in range(len(lines1_batch))]).cuda()\n","        # lines2_batch_lengths = torch.tensor([torch.max(lines2_batch[i].data.nonzero()+1) for i in range(len(lines2_batch))]).cuda()\n","        tag_score = compare_regex_model(lines1_batch, lines2_batch)\n","        targets_batches = targets_idx[batch * batch_size:(batch+1) * batch_size]\n","        # targets_batches = targets_idx\n","        # print(tag_score.squeeze(1), targets_batches)\n","        loss = loss_function(tag_score.squeeze(1).squeeze(1), targets_batches[:, 1])\n","        epoch_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        if batch > 0 and batch % 1000 == 0:\n","          torch.save(compare_regex_model, os.path.join(compare_model_dir, f\"epoch-{epoch}-batch-{batch}.pth\"))\n","          compare_regex_model.tokenizer.save_pretrained(compare_model_dir)\n","        # if batch % 100 == 0:\n","        #   print('iter: {}, batch_loss: {}'.format(batch, loss.item()))\n","    else:\n","      for batch in tqdm.tqdm(range(batch_num)):\n","          compare_regex_model.zero_grad()\n","          # lines1_batch = lines1_seq2idx[batch * batch_size:(batch+1) * batch_size]\n","          # lines2_batch = lines2_seq2idx[batch * batch_size:(batch+1) * batch_size]\n","          lines1_batch = {k: v[batch * batch_size:(batch+1) * batch_size] for k, v in lines1_seq2idx.items()}\n","          lines2_batch = {k: v[batch * batch_size:(batch+1) * batch_size] for k, v in lines2_seq2idx.items()}\n","          # lines1_batch_lengths = torch.tensor([torch.max(lines1_batch[i].data.nonzero()+1) for i in range(len(lines1_batch))]).cuda()\n","          # lines2_batch_lengths = torch.tensor([torch.max(lines2_batch[i].data.nonzero()+1) for i in range(len(lines2_batch))]).cuda()\n","          tag_score = compare_regex_model(lines1_batch, lines2_batch)\n","          targets_batches = targets_idx[batch * batch_size:(batch+1) * batch_size]\n","          # targets_batches = targets_idx\n","          # print(tag_score.squeeze(1), targets_batches)\n","          loss = loss_function(tag_score.squeeze(1).squeeze(1), targets_batches[:, 1])\n","          epoch_loss += loss.item()\n","          loss.backward()\n","          optimizer.step()\n","          if batch > 0 and batch % 1000 == 0:\n","            torch.save(compare_regex_model, os.path.join(compare_model_dir, f\"epoch-{epoch}-batch-{batch}.pth\"))\n","            compare_regex_model.tokenizer.save_pretrained(compare_model_dir)\n","          # if batch % 100 == 0:\n","          #   print('iter: {}, batch_loss: {}'.format(batch, loss.item()))\n","    \n","    with torch.no_grad():\n","        test_acc = evaluate_test(compare_regex_model, test_input1, test_input2, test_targets)\n","        print('step:{}, test acc: {}'.format(epoch, test_acc))\n","    \n","    if test_acc == 1.0:\n","        break\n","    print('epoch: {}, epoch_loss: {}'.format(epoch,epoch_loss/batch_num))\n","    torch.save(compare_regex_model, os.path.join(compare_model_dir, 'epoch-{}.pth'.format(epoch)))\n","    compare_regex_model.tokenizer.save_pretrained(compare_model_dir)\n"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["num_batches: 5823\n"]},{"output_type":"stream","name":"stderr","text":["  0%|                                                                                         | 0/4822 [00:08<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13868/2316738835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# lines1_batch_lengths = torch.tensor([torch.max(lines1_batch[i].data.nonzero()+1) for i in range(len(lines1_batch))]).cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# lines2_batch_lengths = torch.tensor([torch.max(lines2_batch[i].data.nonzero()+1) for i in range(len(lines2_batch))]).cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mtag_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_regex_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines1_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines2_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mtargets_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# targets_batches = targets_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13868/3556595147.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, line1, line2)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mbert1_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert1_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mbert2_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mline2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mbert2_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert2_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# bert2_output = self.bert2(input_ids=line2[\"input_ids\"],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         )\n\u001b[1;32m--> 853\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 )\n\u001b[0;32m    525\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    527\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         )\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   2359\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2361\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1554\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1556\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 8.00 GiB total capacity; 6.57 GiB already allocated; 0 bytes free; 6.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"id":"WmomsASLl0qe"},"source":["batch_num = int(len(lines1_seq2idx)/batch_size)\n","\n","with torch.no_grad():\n","    test_acc = evaluate_test(compare_regex_model, test_input1, test_input2, test_targets)\n","    print('test acc: {}'.format(test_acc))\n","    \n","    print('epoch: {}, epoch_loss: {}'.format(epoch,epoch_loss/batch_num))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpOKV1pyl0qg"},"source":["torch.save(compare_regex_model, './compare_regex_model_share2.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDnqUEyel0qh"},"source":["import os\n","compare_regex_model = torch.load(os.path.join(compare_model_dir, 'epoch-{}.pth'.format(0)), map_location=torch.device('cpu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZ5Qri1ql0qi"},"source":["### single input test"]},{"cell_type":"code","metadata":{"id":"VusZC0rXl0qj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639113433332,"user_tz":480,"elapsed":189,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"baffeaa2-4839-4086-bd86-17499b9a71e0"},"source":["gold = ['( ( <M0> ) & ( [ <LET> ] ) ) . * ( [ <CAP> ] ) . *']\n","predict = ['( <M0> ) . * ( ( [ <CAP> ] ) & ( [ <CAP> ] ) ) . *']\n","target = [0]\n","gold_input, predict_input, target_input = make_input_seq(gold, predict, target)\n","# gold_len = torch.tensor([torch.max(gold_input[0].data.nonzero()+1)])\n","# predict_len = torch.tensor([torch.max(predict_input[0].data.nonzero()+1)])\n","print(predict_input)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[   0,   12,  225, 1000,  225,   13,  225,   18,  225,   14,  225,   12,\n","          225,   12,  225,   63,  225, 1008,  225,   65,  225,   13,  225,   10,\n","          225,   12,  225,   63,  225, 1008,  225,   65,  225,   13,  225,   13,\n","          225,   18,  225,   14,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rq-KlChtSej","executionInfo":{"status":"ok","timestamp":1639113433333,"user_tz":480,"elapsed":7,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"d3777a42-6fc1-4d05-db3a-54739e6f86c0"},"source":["compare_regex_model(gold_input, predict_input)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.6959, -0.6904]], grad_fn=<LogSoftmaxBackward0>)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["evaluate_test(compare_regex_model, test_input1, test_input2, test_targets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0w7EcN7ftkhl","executionInfo":{"status":"ok","timestamp":1639113684274,"user_tz":480,"elapsed":250944,"user":{"displayName":"Parth Baokar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTr0F0GxdJiWND7WqOvJ5YHc3aW3a2XD5sEKvS=s64","userId":"03945953594447876238"}},"outputId":"44cfb3f9-a8fe-4785-dfb4-7ee8b9319db3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5297\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["precision: 0.37724935732647813,recall: 0.8884964682139254,f1 score:0.529624060150376\n","total: 5297, correct: 0\n"]},{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"vD7fGohYl0qk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639078406080,"user_tz":480,"elapsed":132,"user":{"displayName":"Kunal Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2IyyPs0gtDZ0y5efw94mocEVIc6hbCkoEp2F4=s64","userId":"16336361098390008573"}},"outputId":"6f768d67-178d-4239-838a-5242bbb4c9d7"},"source":["snew_vocab = dict(map(reversed, vocab.items()))\n","print(new_vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{1: '', 2: '<M0>', 13: 'b', 3: '[', 14: '(', 4: ',', 6: '<M3>', 16: '.', 17: '\\\\', 18: '<M1>', 19: '*', 12: '<LOW>', 5: '{', 21: '}', 22: '<M2>', 24: ']', 0: '<pad>', 25: '|', 7: '+', 8: '6', 27: '<LET>', 26: '&', 28: '<VOW>', 23: '<NUM>', 9: '4', 29: '~', 31: '7', 10: '3', 11: ')', 15: '5', 30: '<CAP>', 20: '2'}\n"]}]},{"cell_type":"code","metadata":{"id":"WvrUCJOEl0ql","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"error","timestamp":1639078409976,"user_tz":480,"elapsed":162,"user":{"displayName":"Kunal Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2IyyPs0gtDZ0y5efw94mocEVIc6hbCkoEp2F4=s64","userId":"16336361098390008573"}},"outputId":"daa8ab87-91f8-4295-98bf-171346102159"},"source":["' '.join([new_vocab[j] for j in [i for i in gold_input.tolist()[0]]]).replace('<pad>','')\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'tolist'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-646a89246c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"e3vdT-hOl0qm"},"source":["import math\n","with torch.no_grad():\n","    score = compare_regex_model(1, gold_input, predict_input, [gold_len], [predict_len])\n","    print(math.exp(score[0][0]))\n","    print(math.exp(score[0][1]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"48plLaQHl0qm"},"source":["f = open('../pair_data/test.txt','r')\n","\n","\n","total_set = set()\n","lines1 = list()\n","lines2 = list()\n","targets = list()\n","\n","count = 0\n","for line in f.read().splitlines():\n","    count += 1\n","    total_set.add(line)\n","    splitted = line.split('\\t')\n","#     total_set.add('{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2]))\n","print(count)\n","\n","count = 0\n","for line in total_set:\n","    count += 1\n","    splitted = line.split('\\t')\n","    lines1.append(splitted[0])\n","    lines2.append(splitted[1])\n","    targets.append(splitted[2])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmYXOGQTl0qn"},"source":["test_input1, test_input2, test_targets = make_input_seq(lines1, lines2, targets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aTGNrjKrl0qo"},"source":["with torch.no_grad():\n","        print('test acc: {}'.format(evaluate_test(compare_regex_model, test_input1, test_input2,  test_targets)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yW7-iwDNsGiR","executionInfo":{"status":"ok","timestamp":1639078458442,"user_tz":480,"elapsed":313,"user":{"displayName":"Kunal Agarwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2IyyPs0gtDZ0y5efw94mocEVIc6hbCkoEp2F4=s64","userId":"16336361098390008573"}},"outputId":"1f51e4b2-fe7d-47bf-981a-db88b7e1caf8"},"source":["compare_regex_model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["compare_regex_bert(\n","  (embed): Embedding(32, 768, padding_idx=0)\n","  (bert1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(1009, 768)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert2): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(1009, 768)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc1): Linear(in_features=768, out_features=60, bias=True)\n","  (fc2): Linear(in_features=60, out_features=20, bias=True)\n","  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"J30_fVrEsHBx"},"source":[""],"execution_count":null,"outputs":[]}]}